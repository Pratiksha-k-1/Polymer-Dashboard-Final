Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_204229'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.18 GB / 8.00 GB (14.7%)
Disk Space Avail:   24.25 GB / 228.27 GB (10.6%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 4,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 89 rows, 1 time series. Median time series length is 89 (min=89, max=89). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 21:42:29
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-0.8049       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.09    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 59.9s of remaining time.
	-0.9006       = Validation score (-MASE)
	0.54    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.3s of remaining time.
	-2.0236       = Validation score (-MASE)
	0.29    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.8s of the 59.0s of remaining time.
	-0.8049       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.7s of the 59.0s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.7s of the 59.0s of remaining time.
	-1.1384       = Validation score (-MASE)
	0.71    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 29.1s of the 58.2s of remaining time.
	-0.8253       = Validation score (-MASE)
	26.33   s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 31.9s.
	Ensemble weights: {'Chronos2': 0.49, 'DirectTabular': 0.34, 'SeasonalNaive': 0.17}
	-0.6661       = Validation score (-MASE)
	0.08    s     = Training runtime
	0.14    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 28.23 s
Best model: WeightedEnsemble
Best model score: -0.6661
Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_204259"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_204259'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.18 GB / 8.00 GB (14.7%)
Disk Space Avail:   24.25 GB / 228.27 GB (10.6%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 4,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 90 rows, 1 time series. Median time series length is 90 (min=90, max=90). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 21:42:59
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-1.4808       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 60.0s of remaining time.
	-0.9959       = Validation score (-MASE)
	0.49    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.4s of remaining time.
	-2.5837       = Validation score (-MASE)
	0.29    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.8s of the 59.1s of remaining time.
	-1.4808       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.8s of the 59.1s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.7s of the 59.1s of remaining time.
	-0.9275       = Validation score (-MASE)
	0.77    s     = Training runtime
	0.52    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 28.9s of the 57.8s of remaining time.
	-1.5021       = Validation score (-MASE)
	26.32   s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 31.4s.
	Ensemble weights: {'Chronos2': 0.89, 'DirectTabular': 0.11}
	-0.9047       = Validation score (-MASE)
	0.16    s     = Training runtime
	0.54    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 28.84 s
Best model: WeightedEnsemble
Best model score: -0.9047
Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_204329"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_204329'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.07 GB / 8.00 GB (13.4%)
Disk Space Avail:   24.25 GB / 228.27 GB (10.6%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 4,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 91 rows, 1 time series. Median time series length is 91 (min=91, max=91). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 21:43:29
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-2.6875       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.06    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 59.9s of remaining time.
	-2.0113       = Validation score (-MASE)
	0.76    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.1s of remaining time.
	-3.1076       = Validation score (-MASE)
	0.47    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.7s of the 58.6s of remaining time.
	-2.6875       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.10    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.6s of the 58.5s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.5s of the 58.5s of remaining time.
	-1.9764       = Validation score (-MASE)
	0.94    s     = Training runtime
	0.27    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 28.6s of the 57.3s of remaining time.
	-2.6170       = Validation score (-MASE)
	25.97   s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 31.2s.
	Ensemble weights: {'Chronos2': 1.0}
	-1.9764       = Validation score (-MASE)
	0.14    s     = Training runtime
	0.27    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 28.96 s
Best model: Chronos2
Best model score: -1.9764
Model not specified in predict, will default to the model with the best validation score: Chronos2
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_204359"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_204359'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.20 GB / 8.00 GB (15.0%)
Disk Space Avail:   24.25 GB / 228.27 GB (10.6%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 4,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 92 rows, 1 time series. Median time series length is 92 (min=92, max=92). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 21:43:59
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-4.8000       = Validation score (-MASE)
	0.01    s     = Training runtime
	2.43    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.2s of the 57.5s of remaining time.
	-4.1945       = Validation score (-MASE)
	0.67    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.5s of the 56.8s of remaining time.
	-4.8177       = Validation score (-MASE)
	0.54    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.3s of the 56.3s of remaining time.
	-4.7999       = Validation score (-MASE)
	0.01    s     = Training runtime
	1.66    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 13.6s of the 54.6s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 18.2s of the 54.6s of remaining time.
	-4.0836       = Validation score (-MASE)
	0.77    s     = Training runtime
	0.34    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 26.7s of the 53.5s of remaining time.
	-4.3011       = Validation score (-MASE)
	24.24   s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 29.2s.
	Ensemble weights: {'Chronos2': 1.0}
	-4.0836       = Validation score (-MASE)
	0.14    s     = Training runtime
	0.34    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 31.03 s
Best model: Chronos2
Best model score: -4.0836
Model not specified in predict, will default to the model with the best validation score: Chronos2
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_204431"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_204431'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.07 GB / 8.00 GB (13.3%)
Disk Space Avail:   24.24 GB / 228.27 GB (10.6%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 4,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 93 rows, 1 time series. Median time series length is 93 (min=93, max=93). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 21:44:31
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-3.2267       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 59.9s of remaining time.
	-2.7374       = Validation score (-MASE)
	0.70    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.2s of remaining time.
	-5.8043       = Validation score (-MASE)
	0.56    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.7s of the 58.6s of remaining time.
	-3.2270       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.05    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.6s of the 58.5s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.5s of the 58.5s of remaining time.
	-2.2388       = Validation score (-MASE)
	0.78    s     = Training runtime
	0.19    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 28.8s of the 57.6s of remaining time.
	-5.8989       = Validation score (-MASE)
	26.08   s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 31.4s.
	Ensemble weights: {'Chronos2': 1.0}
	-2.2388       = Validation score (-MASE)
	0.15    s     = Training runtime
	0.19    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 28.76 s
Best model: Chronos2
Best model score: -2.2388
Model not specified in predict, will default to the model with the best validation score: Chronos2
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_204501"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_204501'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.11 GB / 8.00 GB (13.8%)
Disk Space Avail:   24.24 GB / 228.27 GB (10.6%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 4,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 94 rows, 1 time series. Median time series length is 94 (min=94, max=94). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 21:45:01
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-4.7467       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 59.9s of remaining time.
	-4.8229       = Validation score (-MASE)
	0.70    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.2s of remaining time.
	-6.7858       = Validation score (-MASE)
	0.61    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.7s of the 58.5s of remaining time.
	-4.7467       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.05    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.6s of the 58.5s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.5s of the 58.5s of remaining time.
	-3.6135       = Validation score (-MASE)
	0.79    s     = Training runtime
	0.33    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 28.7s of the 57.3s of remaining time.
	-7.1949       = Validation score (-MASE)
	26.15   s     = Training runtime
	0.05    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 31.0s.
	Ensemble weights: {'Chronos2': 1.0}
	-3.6135       = Validation score (-MASE)
	0.37    s     = Training runtime
	0.33    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 29.48 s
Best model: Chronos2
Best model score: -3.6135
Model not specified in predict, will default to the model with the best validation score: Chronos2
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_204555"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_204555'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.01 GB / 8.00 GB (12.6%)
Disk Space Avail:   23.24 GB / 228.27 GB (10.2%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 7,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 80 rows, 1 time series. Median time series length is 80 (min=80, max=80). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 21:45:55
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-1.6887       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.06    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 59.9s of remaining time.
	-1.7683       = Validation score (-MASE)
	0.70    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.1s of remaining time.
	-5.1725       = Validation score (-MASE)
	0.38    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.7s of the 58.7s of remaining time.
	-1.6889       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.05    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.7s of the 58.7s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.6s of the 58.7s of remaining time.
	-1.2927       = Validation score (-MASE)
	0.92    s     = Training runtime
	0.37    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 28.7s of the 57.4s of remaining time.
	-4.7301       = Validation score (-MASE)
	26.04   s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 31.3s.
	Ensemble weights: {'Chronos2': 0.43, 'ETS': 0.14, 'SeasonalNaive': 0.43}
	-1.1681       = Validation score (-MASE)
	0.12    s     = Training runtime
	0.48    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 28.89 s
Best model: WeightedEnsemble
Best model score: -1.1681
Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_204625"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_204625'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       0.99 GB / 8.00 GB (12.4%)
Disk Space Avail:   23.24 GB / 228.27 GB (10.2%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 7,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 81 rows, 1 time series. Median time series length is 81 (min=81, max=81). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 21:46:25
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-1.5450       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 60.0s of remaining time.
	-1.5950       = Validation score (-MASE)
	0.46    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.5s of remaining time.
	-5.4809       = Validation score (-MASE)
	0.30    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.8s of the 59.2s of remaining time.
	-1.5450       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.8s of the 59.1s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.7s of the 59.1s of remaining time.
	-1.2790       = Validation score (-MASE)
	0.77    s     = Training runtime
	0.23    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 29.1s of the 58.1s of remaining time.
	-1.5244       = Validation score (-MASE)
	26.33   s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 31.7s.
	Ensemble weights: {'Chronos2': 0.75, 'TemporalFusionTransformer': 0.25}
	-1.1640       = Validation score (-MASE)
	0.15    s     = Training runtime
	0.28    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 28.54 s
Best model: WeightedEnsemble
Best model score: -1.1640
Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_204656"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_204656'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.30 GB / 8.00 GB (16.3%)
Disk Space Avail:   23.23 GB / 228.27 GB (10.2%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 7,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 82 rows, 1 time series. Median time series length is 82 (min=82, max=82). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 21:46:56
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-1.9577       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.11    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 59.9s of remaining time.
	-1.3384       = Validation score (-MASE)
	0.77    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.8s of the 59.0s of remaining time.
	-5.9445       = Validation score (-MASE)
	0.41    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.7s of the 58.6s of remaining time.
	-1.9577       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.05    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.6s of the 58.5s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.5s of the 58.5s of remaining time.
	-2.2874       = Validation score (-MASE)
	0.73    s     = Training runtime
	0.32    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 28.7s of the 57.5s of remaining time.
	-2.9216       = Validation score (-MASE)
	25.99   s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 31.4s.
	Ensemble weights: {'RecursiveTabular': 1.0}
	-1.3384       = Validation score (-MASE)
	0.07    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 28.64 s
Best model: RecursiveTabular
Best model score: -1.3384
Model not specified in predict, will default to the model with the best validation score: RecursiveTabular
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_204724"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_204724'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.41 GB / 8.00 GB (17.6%)
Disk Space Avail:   23.23 GB / 228.27 GB (10.2%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 7,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 83 rows, 1 time series. Median time series length is 83 (min=83, max=83). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 21:47:24
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-2.3016       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.07    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 59.9s of remaining time.
	-1.6664       = Validation score (-MASE)
	0.38    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.5s of remaining time.
	-6.3540       = Validation score (-MASE)
	0.25    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.8s of the 59.2s of remaining time.
	-2.3016       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.99    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.6s of the 58.2s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.4s of the 58.2s of remaining time.
	-3.0445       = Validation score (-MASE)
	0.71    s     = Training runtime
	0.30    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 28.6s of the 57.2s of remaining time.
	-1.3829       = Validation score (-MASE)
	25.88   s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 31.3s.
	Ensemble weights: {'TemporalFusionTransformer': 1.0}
	-1.3829       = Validation score (-MASE)
	0.08    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 28.84 s
Best model: TemporalFusionTransformer
Best model score: -1.3829
Model not specified in predict, will default to the model with the best validation score: TemporalFusionTransformer
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_204753"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_204753'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.34 GB / 8.00 GB (16.8%)
Disk Space Avail:   24.22 GB / 228.27 GB (10.6%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 7,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 84 rows, 1 time series. Median time series length is 84 (min=84, max=84). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 21:47:53
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-2.6138       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 59.9s of remaining time.
	-2.6351       = Validation score (-MASE)
	0.41    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.5s of remaining time.
	-6.7376       = Validation score (-MASE)
	0.26    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.8s of the 59.2s of remaining time.
	-2.6138       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.8s of the 59.2s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.7s of the 59.2s of remaining time.
	-3.6016       = Validation score (-MASE)
	0.79    s     = Training runtime
	0.34    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 29.0s of the 58.1s of remaining time.
	-0.9810       = Validation score (-MASE)
	26.27   s     = Training runtime
	0.06    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 31.7s.
	Ensemble weights: {'TemporalFusionTransformer': 1.0}
	-0.9810       = Validation score (-MASE)
	0.07    s     = Training runtime
	0.06    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 28.39 s
Best model: TemporalFusionTransformer
Best model score: -0.9810
Model not specified in predict, will default to the model with the best validation score: TemporalFusionTransformer
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_204822"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_204822'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.32 GB / 8.00 GB (16.6%)
Disk Space Avail:   24.22 GB / 228.27 GB (10.6%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 7,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 85 rows, 1 time series. Median time series length is 85 (min=85, max=85). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 21:48:22
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-0.2357       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 60.0s of remaining time.
	-3.6619       = Validation score (-MASE)
	0.52    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.4s of remaining time.
	-2.9588       = Validation score (-MASE)
	0.55    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.8s of the 58.8s of remaining time.
	-0.2358       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.7s of the 58.8s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.6s of the 58.8s of remaining time.
	-2.0070       = Validation score (-MASE)
	0.80    s     = Training runtime
	0.29    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 28.9s of the 57.7s of remaining time.
	-1.4039       = Validation score (-MASE)
	26.09   s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 31.6s.
	Ensemble weights: {'SeasonalNaive': 1.0}
	-0.2357       = Validation score (-MASE)
	0.07    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 28.50 s
Best model: SeasonalNaive
Best model score: -0.2357
Model not specified in predict, will default to the model with the best validation score: SeasonalNaive
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_204850"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_204850'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.30 GB / 8.00 GB (16.2%)
Disk Space Avail:   24.22 GB / 228.27 GB (10.6%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 7,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 86 rows, 1 time series. Median time series length is 86 (min=86, max=86). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 21:48:50
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-0.2786       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 60.0s of remaining time.
	-0.3313       = Validation score (-MASE)
	0.39    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.6s of remaining time.
	-3.2868       = Validation score (-MASE)
	0.39    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.8s of the 59.1s of remaining time.
	-0.2786       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.8s of the 59.1s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.7s of the 59.1s of remaining time.
	-0.7566       = Validation score (-MASE)
	0.73    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 29.2s of the 58.4s of remaining time.
	-1.0753       = Validation score (-MASE)
	26.34   s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 32.0s.
	Ensemble weights: {'SeasonalNaive': 1.0}
	-0.2786       = Validation score (-MASE)
	0.07    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 28.11 s
Best model: SeasonalNaive
Best model score: -0.2786
Model not specified in predict, will default to the model with the best validation score: SeasonalNaive
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_204918"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_204918'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.30 GB / 8.00 GB (16.2%)
Disk Space Avail:   24.22 GB / 228.27 GB (10.6%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 7,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 87 rows, 1 time series. Median time series length is 87 (min=87, max=87). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 21:49:18
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-0.3628       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 60.0s of remaining time.
	-0.4725       = Validation score (-MASE)
	0.37    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.6s of remaining time.
	-4.6810       = Validation score (-MASE)
	2.14    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.5s of the 57.4s of remaining time.
	-0.3628       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.3s of the 57.4s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.1s of the 57.4s of remaining time.
	-0.2559       = Validation score (-MASE)
	0.81    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 28.3s of the 56.5s of remaining time.
	-0.6436       = Validation score (-MASE)
	25.52   s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 31.0s.
	Ensemble weights: {'Chronos2': 0.91, 'SeasonalNaive': 0.09}
	-0.2438       = Validation score (-MASE)
	0.07    s     = Training runtime
	0.06    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 29.14 s
Best model: WeightedEnsemble
Best model score: -0.2438
Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_204948"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_204948'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.27 GB / 8.00 GB (15.9%)
Disk Space Avail:   24.21 GB / 228.27 GB (10.6%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 7,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 88 rows, 1 time series. Median time series length is 88 (min=88, max=88). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 21:49:48
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-0.3673       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 60.0s of remaining time.
	-0.5298       = Validation score (-MASE)
	0.36    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.6s of remaining time.
	-2.4488       = Validation score (-MASE)
	0.37    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.8s of the 59.2s of remaining time.
	-0.3673       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.8s of the 59.2s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.7s of the 59.2s of remaining time.
	-0.4965       = Validation score (-MASE)
	0.75    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 29.2s of the 58.4s of remaining time.
	-0.3401       = Validation score (-MASE)
	26.37   s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 32.0s.
	Ensemble weights: {'SeasonalNaive': 0.26, 'TemporalFusionTransformer': 0.74}
	-0.3260       = Validation score (-MASE)
	0.07    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 28.12 s
Best model: WeightedEnsemble
Best model score: -0.3260
Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_205017"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_205017'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.24 GB / 8.00 GB (15.5%)
Disk Space Avail:   24.21 GB / 228.27 GB (10.6%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 7,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 89 rows, 1 time series. Median time series length is 89 (min=89, max=89). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 21:50:17
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-0.7852       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 60.0s of remaining time.
	-0.9647       = Validation score (-MASE)
	0.37    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.6s of remaining time.
	-3.6140       = Validation score (-MASE)
	0.89    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.7s of the 58.7s of remaining time.
	-0.7852       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.7s of the 58.7s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.6s of the 58.7s of remaining time.
	-1.0291       = Validation score (-MASE)
	0.77    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 28.9s of the 57.8s of remaining time.
	-0.5920       = Validation score (-MASE)
	26.12   s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 31.7s.
	Ensemble weights: {'Chronos2': 0.17, 'SeasonalNaive': 0.15, 'TemporalFusionTransformer': 0.68}
	-0.5465       = Validation score (-MASE)
	0.07    s     = Training runtime
	0.07    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 28.44 s
Best model: WeightedEnsemble
Best model score: -0.5465
Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_205046"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_205046'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.22 GB / 8.00 GB (15.3%)
Disk Space Avail:   24.21 GB / 228.27 GB (10.6%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 7,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 90 rows, 1 time series. Median time series length is 90 (min=90, max=90). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 21:50:46
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-1.5370       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 60.0s of remaining time.
	-1.7713       = Validation score (-MASE)
	0.36    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.6s of remaining time.
	-2.7389       = Validation score (-MASE)
	0.50    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.8s of the 59.1s of remaining time.
	-1.5369       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.8s of the 59.0s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.7s of the 59.0s of remaining time.
	-0.7412       = Validation score (-MASE)
	0.78    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 29.1s of the 58.2s of remaining time.
	-0.8398       = Validation score (-MASE)
	26.29   s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 31.9s.
	Ensemble weights: {'Chronos2': 0.6, 'TemporalFusionTransformer': 0.4}
	-0.7339       = Validation score (-MASE)
	0.09    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 28.23 s
Best model: WeightedEnsemble
Best model score: -0.7339
Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_205115"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_205115'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.25 GB / 8.00 GB (15.7%)
Disk Space Avail:   24.21 GB / 228.27 GB (10.6%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 7,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 91 rows, 1 time series. Median time series length is 91 (min=91, max=91). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 21:51:15
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-2.7234       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 60.0s of remaining time.
	-2.9711       = Validation score (-MASE)
	0.34    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.6s of remaining time.
	-3.3325       = Validation score (-MASE)
	0.52    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.8s of the 59.1s of remaining time.
	-2.7233       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.8s of the 59.0s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.7s of the 59.0s of remaining time.
	-1.6256       = Validation score (-MASE)
	0.73    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 29.1s of the 58.3s of remaining time.
	-1.5741       = Validation score (-MASE)
	26.34   s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 31.9s.
	Ensemble weights: {'Chronos2': 0.15, 'TemporalFusionTransformer': 0.85}
	-1.5500       = Validation score (-MASE)
	0.07    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 28.20 s
Best model: WeightedEnsemble
Best model score: -1.5500
Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_210351"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_210351'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.18 GB / 8.00 GB (14.7%)
Disk Space Avail:   25.21 GB / 228.27 GB (11.0%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 1,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 82 rows, 1 time series. Median time series length is 82 (min=82, max=82). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 22:03:51
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	0.0000        = Validation score (-MASE)
	0.01    s     = Training runtime
	2.18    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.2s of the 57.7s of remaining time.
	-0.0472       = Validation score (-MASE)
	0.79    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.5s of the 56.9s of remaining time.
	-0.0046       = Validation score (-MASE)
	0.33    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.3s of the 56.6s of remaining time.
	0.0000        = Validation score (-MASE)
	0.01    s     = Training runtime
	2.56    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 13.5s of the 54.0s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 18.0s of the 54.0s of remaining time.
	-0.4346       = Validation score (-MASE)
	0.91    s     = Training runtime
	0.38    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 26.3s of the 52.7s of remaining time.
	-0.2045       = Validation score (-MASE)
	23.85   s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 28.8s.
	Ensemble weights: {'SeasonalNaive': 1.0}
	0.0000        = Validation score (-MASE)
	0.07    s     = Training runtime
	2.18    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 31.28 s
Best model: SeasonalNaive
Best model score: 0.0000
Model not specified in predict, will default to the model with the best validation score: SeasonalNaive
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_210424"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_210424'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.30 GB / 8.00 GB (16.2%)
Disk Space Avail:   25.21 GB / 228.27 GB (11.0%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 1,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 83 rows, 1 time series. Median time series length is 83 (min=83, max=83). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 22:04:24
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-0.5786       = Validation score (-MASE)
	0.01    s     = Training runtime
	1.06    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.4s of the 58.9s of remaining time.
	-0.5791       = Validation score (-MASE)
	0.44    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.7s of the 58.5s of remaining time.
	-0.5752       = Validation score (-MASE)
	0.29    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.6s of the 58.2s of remaining time.
	-0.5786       = Validation score (-MASE)
	0.00    s     = Training runtime
	1.89    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.1s of the 56.2s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 18.7s of the 56.2s of remaining time.
	-0.7636       = Validation score (-MASE)
	0.80    s     = Training runtime
	0.38    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 27.5s of the 55.1s of remaining time.
	-0.2663       = Validation score (-MASE)
	24.87   s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 30.2s.
	Ensemble weights: {'TemporalFusionTransformer': 1.0}
	-0.2663       = Validation score (-MASE)
	0.07    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 29.94 s
Best model: TemporalFusionTransformer
Best model score: -0.2663
Model not specified in predict, will default to the model with the best validation score: TemporalFusionTransformer
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_210454"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_210454'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.21 GB / 8.00 GB (15.1%)
Disk Space Avail:   24.22 GB / 228.27 GB (10.6%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 1,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 84 rows, 1 time series. Median time series length is 84 (min=84, max=84). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 22:04:54
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-0.2908       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 60.0s of remaining time.
	-0.6164       = Validation score (-MASE)
	0.49    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.5s of remaining time.
	-0.6084       = Validation score (-MASE)
	0.27    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.8s of the 59.2s of remaining time.
	-0.2908       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.77    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.6s of the 58.4s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.5s of the 58.4s of remaining time.
	-0.3864       = Validation score (-MASE)
	0.76    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 28.8s of the 57.6s of remaining time.
	-0.1654       = Validation score (-MASE)
	26.06   s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 31.5s.
	Ensemble weights: {'SeasonalNaive': 0.36, 'TemporalFusionTransformer': 0.64}
	-0.0000       = Validation score (-MASE)
	0.08    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 28.62 s
Best model: WeightedEnsemble
Best model score: -0.0000
Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_210522"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_210522'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.15 GB / 8.00 GB (14.3%)
Disk Space Avail:   24.22 GB / 228.27 GB (10.6%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 1,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 85 rows, 1 time series. Median time series length is 85 (min=85, max=85). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 22:05:22
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-1.1731       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 60.0s of remaining time.
	-1.2698       = Validation score (-MASE)
	0.47    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.5s of remaining time.
	-1.2275       = Validation score (-MASE)
	0.30    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.8s of the 59.2s of remaining time.
	-1.1731       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.70    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.6s of the 58.5s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.5s of the 58.4s of remaining time.
	-0.9785       = Validation score (-MASE)
	0.75    s     = Training runtime
	0.30    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 28.7s of the 57.4s of remaining time.
	-0.5180       = Validation score (-MASE)
	25.96   s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 31.4s.
	Ensemble weights: {'TemporalFusionTransformer': 1.0}
	-0.5180       = Validation score (-MASE)
	0.07    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 28.72 s
Best model: TemporalFusionTransformer
Best model score: -0.5180
Model not specified in predict, will default to the model with the best validation score: TemporalFusionTransformer
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_210551"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_210551'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.33 GB / 8.00 GB (16.6%)
Disk Space Avail:   24.21 GB / 228.27 GB (10.6%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 1,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 86 rows, 1 time series. Median time series length is 86 (min=86, max=86). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 22:05:51
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	0.0000        = Validation score (-MASE)
	0.00    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 59.9s of remaining time.
	-0.2005       = Validation score (-MASE)
	0.46    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.5s of remaining time.
	-0.0306       = Validation score (-MASE)
	0.32    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.8s of the 59.1s of remaining time.
	-0.0001       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.77    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.6s of the 58.4s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.5s of the 58.4s of remaining time.
	-0.8755       = Validation score (-MASE)
	0.81    s     = Training runtime
	0.34    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 28.6s of the 57.2s of remaining time.
	-0.0490       = Validation score (-MASE)
	25.84   s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 31.3s.
	Ensemble weights: {'SeasonalNaive': 1.0}
	0.0000        = Validation score (-MASE)
	0.07    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 28.78 s
Best model: SeasonalNaive
Best model score: 0.0000
Model not specified in predict, will default to the model with the best validation score: SeasonalNaive
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_210620"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_210620'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.33 GB / 8.00 GB (16.7%)
Disk Space Avail:   24.21 GB / 228.27 GB (10.6%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 1,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 87 rows, 1 time series. Median time series length is 87 (min=87, max=87). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 22:06:20
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-0.2962       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 59.9s of remaining time.
	-0.2414       = Validation score (-MASE)
	0.46    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.5s of remaining time.
	-0.2949       = Validation score (-MASE)
	0.30    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.8s of the 59.2s of remaining time.
	-0.2962       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.8s of the 59.1s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.7s of the 59.1s of remaining time.
	-0.2766       = Validation score (-MASE)
	0.75    s     = Training runtime
	0.18    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 29.1s of the 58.2s of remaining time.
	-0.0160       = Validation score (-MASE)
	26.29   s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 31.9s.
	Ensemble weights: {'DirectTabular': 0.18, 'RecursiveTabular': 0.18, 'TemporalFusionTransformer': 0.65}
	-0.0010       = Validation score (-MASE)
	0.07    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 28.24 s
Best model: WeightedEnsemble
Best model score: -0.0010
Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_210648"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_210648'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.29 GB / 8.00 GB (16.1%)
Disk Space Avail:   24.21 GB / 228.27 GB (10.6%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 1,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 88 rows, 1 time series. Median time series length is 88 (min=88, max=88). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 22:06:48
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-0.5972       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 60.0s of remaining time.
	-0.9059       = Validation score (-MASE)
	0.47    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.5s of remaining time.
	-0.9050       = Validation score (-MASE)
	0.34    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.8s of the 59.1s of remaining time.
	-0.5972       = Validation score (-MASE)
	0.00    s     = Training runtime
	2.39    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.2s of the 56.7s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 18.9s of the 56.7s of remaining time.
	-1.0052       = Validation score (-MASE)
	0.83    s     = Training runtime
	0.36    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 27.8s of the 55.5s of remaining time.
	-0.0393       = Validation score (-MASE)
	25.12   s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 30.4s.
	Ensemble weights: {'TemporalFusionTransformer': 1.0}
	-0.0393       = Validation score (-MASE)
	0.07    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 29.76 s
Best model: TemporalFusionTransformer
Best model score: -0.0393
Model not specified in predict, will default to the model with the best validation score: TemporalFusionTransformer
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_210718"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_210718'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.41 GB / 8.00 GB (17.6%)
Disk Space Avail:   24.17 GB / 228.27 GB (10.6%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 1,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 89 rows, 1 time series. Median time series length is 89 (min=89, max=89). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 22:07:18
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-3.0000       = Validation score (-MASE)
	0.00    s     = Training runtime
	1.76    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.3s of the 58.2s of remaining time.
	-3.0802       = Validation score (-MASE)
	0.41    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.6s of the 57.8s of remaining time.
	-2.9912       = Validation score (-MASE)
	0.30    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.5s of the 57.5s of remaining time.
	-2.9999       = Validation score (-MASE)
	0.01    s     = Training runtime
	1.88    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 13.9s of the 55.6s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 18.5s of the 55.6s of remaining time.
	-2.6712       = Validation score (-MASE)
	0.76    s     = Training runtime
	0.36    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 27.2s of the 54.5s of remaining time.
	-2.5637       = Validation score (-MASE)
	24.60   s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 29.8s.
	Ensemble weights: {'TemporalFusionTransformer': 1.0}
	-2.5637       = Validation score (-MASE)
	0.07    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 30.28 s
Best model: TemporalFusionTransformer
Best model score: -2.5637
Model not specified in predict, will default to the model with the best validation score: TemporalFusionTransformer
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_210748"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_210748'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.28 GB / 8.00 GB (16.0%)
Disk Space Avail:   24.17 GB / 228.27 GB (10.6%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 1,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 90 rows, 1 time series. Median time series length is 90 (min=90, max=90). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 22:07:48
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	0.0000        = Validation score (-MASE)
	0.00    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 60.0s of remaining time.
	-0.4434       = Validation score (-MASE)
	0.42    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.5s of remaining time.
	-3.6220       = Validation score (-MASE)
	0.33    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.8s of the 59.2s of remaining time.
	-0.0003       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.8s of the 59.1s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.7s of the 59.1s of remaining time.
	-1.1461       = Validation score (-MASE)
	0.73    s     = Training runtime
	0.36    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 29.0s of the 58.0s of remaining time.
	-2.1392       = Validation score (-MASE)
	26.21   s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 31.8s.
	Ensemble weights: {'SeasonalNaive': 1.0}
	0.0000        = Validation score (-MASE)
	0.07    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 28.31 s
Best model: SeasonalNaive
Best model score: 0.0000
Model not specified in predict, will default to the model with the best validation score: SeasonalNaive
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_210817"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_210817'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.16 GB / 8.00 GB (14.5%)
Disk Space Avail:   24.16 GB / 228.27 GB (10.6%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 1,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 91 rows, 1 time series. Median time series length is 91 (min=91, max=91). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 22:08:17
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-2.9667       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 60.0s of remaining time.
	-3.0114       = Validation score (-MASE)
	0.43    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.5s of remaining time.
	-5.9548       = Validation score (-MASE)
	0.34    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.8s of the 59.1s of remaining time.
	-2.9667       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.8s of the 59.1s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.7s of the 59.1s of remaining time.
	-2.4319       = Validation score (-MASE)
	0.77    s     = Training runtime
	0.33    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 29.0s of the 58.0s of remaining time.
	-5.1873       = Validation score (-MASE)
	26.23   s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 31.7s.
	Ensemble weights: {'Chronos2': 1.0}
	-2.4319       = Validation score (-MASE)
	0.07    s     = Training runtime
	0.33    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 28.38 s
Best model: Chronos2
Best model score: -2.4319
Model not specified in predict, will default to the model with the best validation score: Chronos2
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_210846"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_210846'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.21 GB / 8.00 GB (15.1%)
Disk Space Avail:   23.17 GB / 228.27 GB (10.1%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 1,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 92 rows, 1 time series. Median time series length is 92 (min=92, max=92). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 22:08:46
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-1.1613       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.05    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 59.9s of remaining time.
	-0.1376       = Validation score (-MASE)
	0.86    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.8s of the 59.0s of remaining time.
	-5.9529       = Validation score (-MASE)
	3.47    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.1s of the 55.5s of remaining time.
	-1.1616       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.05    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 13.9s of the 55.4s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 18.5s of the 55.4s of remaining time.
	-0.2705       = Validation score (-MASE)
	0.75    s     = Training runtime
	0.23    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 27.2s of the 54.5s of remaining time.
	-5.3578       = Validation score (-MASE)
	24.64   s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 29.8s.
	Ensemble weights: {'Chronos2': 0.34, 'RecursiveTabular': 0.66}
	-0.0000       = Validation score (-MASE)
	0.08    s     = Training runtime
	0.24    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 30.34 s
Best model: WeightedEnsemble
Best model score: -0.0000
Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_210918"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_210918'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.20 GB / 8.00 GB (15.0%)
Disk Space Avail:   23.16 GB / 228.27 GB (10.1%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 1,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 93 rows, 1 time series. Median time series length is 93 (min=93, max=93). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 22:09:18
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-1.7389       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 59.9s of remaining time.
	-2.3866       = Validation score (-MASE)
	0.57    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.4s of remaining time.
	-6.8947       = Validation score (-MASE)
	0.47    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.8s of the 58.8s of remaining time.
	-1.7390       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.15    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.7s of the 58.7s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.6s of the 58.7s of remaining time.
	-0.7665       = Validation score (-MASE)
	0.90    s     = Training runtime
	0.42    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 28.7s of the 57.4s of remaining time.
	-5.5085       = Validation score (-MASE)
	26.01   s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 31.2s.
	Ensemble weights: {'Chronos2': 1.0}
	-0.7665       = Validation score (-MASE)
	0.11    s     = Training runtime
	0.42    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 28.98 s
Best model: Chronos2
Best model score: -0.7665
Model not specified in predict, will default to the model with the best validation score: Chronos2
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_210949"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_210949'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.19 GB / 8.00 GB (14.9%)
Disk Space Avail:   23.15 GB / 228.27 GB (10.1%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 1,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 94 rows, 1 time series. Median time series length is 94 (min=94, max=94). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 22:09:49
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	0.0000        = Validation score (-MASE)
	0.01    s     = Training runtime
	0.23    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.5s of the 59.7s of remaining time.
	-0.5389       = Validation score (-MASE)
	0.58    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.1s of remaining time.
	-5.6250       = Validation score (-MASE)
	0.39    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.7s of the 58.7s of remaining time.
	-0.0002       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.14    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.6s of the 58.6s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.5s of the 58.6s of remaining time.
	-1.5755       = Validation score (-MASE)
	0.77    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 28.9s of the 57.8s of remaining time.
	-0.2218       = Validation score (-MASE)
	26.11   s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 31.6s.
	Ensemble weights: {'SeasonalNaive': 1.0}
	0.0000        = Validation score (-MASE)
	0.07    s     = Training runtime
	0.23    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 28.43 s
Best model: SeasonalNaive
Best model score: 0.0000
Model not specified in predict, will default to the model with the best validation score: SeasonalNaive
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_211017"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_211017'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.24 GB / 8.00 GB (15.5%)
Disk Space Avail:   23.14 GB / 228.27 GB (10.1%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 1,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 95 rows, 1 time series. Median time series length is 95 (min=95, max=95). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 22:10:17
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	0.0000        = Validation score (-MASE)
	0.00    s     = Training runtime
	1.87    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.3s of the 58.1s of remaining time.
	-0.0145       = Validation score (-MASE)
	0.42    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.6s of the 57.7s of remaining time.
	-3.6174       = Validation score (-MASE)
	1.28    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.3s of the 56.4s of remaining time.
	-0.0000       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.05    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.1s of the 56.3s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 18.8s of the 56.3s of remaining time.
	-0.8847       = Validation score (-MASE)
	0.73    s     = Training runtime
	0.45    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 27.6s of the 55.1s of remaining time.
	-0.5243       = Validation score (-MASE)
	24.90   s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 30.1s.
	Ensemble weights: {'SeasonalNaive': 1.0}
	0.0000        = Validation score (-MASE)
	0.07    s     = Training runtime
	1.87    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 29.95 s
Best model: SeasonalNaive
Best model score: 0.0000
Model not specified in predict, will default to the model with the best validation score: SeasonalNaive
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_211047"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_211047'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.20 GB / 8.00 GB (15.0%)
Disk Space Avail:   23.14 GB / 228.27 GB (10.1%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 1,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 96 rows, 1 time series. Median time series length is 96 (min=96, max=96). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 22:10:47
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	0.0000        = Validation score (-MASE)
	0.01    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 60.0s of remaining time.
	-0.0038       = Validation score (-MASE)
	0.38    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.6s of remaining time.
	-3.9950       = Validation score (-MASE)
	0.45    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.8s of the 59.1s of remaining time.
	-0.0000       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.87    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.6s of the 58.2s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.4s of the 58.2s of remaining time.
	-0.2695       = Validation score (-MASE)
	0.68    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 28.8s of the 57.5s of remaining time.
	-0.1755       = Validation score (-MASE)
	25.96   s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 31.5s.
	Ensemble weights: {'SeasonalNaive': 1.0}
	0.0000        = Validation score (-MASE)
	0.07    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 28.59 s
Best model: SeasonalNaive
Best model score: 0.0000
Model not specified in predict, will default to the model with the best validation score: SeasonalNaive
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_211116"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_211116'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.20 GB / 8.00 GB (15.0%)
Disk Space Avail:   23.14 GB / 228.27 GB (10.1%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 1,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 97 rows, 1 time series. Median time series length is 97 (min=97, max=97). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 22:11:16
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-2.9688       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.10    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.5s of the 59.8s of remaining time.
	-2.9313       = Validation score (-MASE)
	0.40    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.4s of remaining time.
	-3.3006       = Validation score (-MASE)
	1.73    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.5s of the 57.7s of remaining time.
	-2.9688       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.16    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.4s of the 57.5s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.2s of the 57.5s of remaining time.
	-2.5412       = Validation score (-MASE)
	0.70    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 28.4s of the 56.8s of remaining time.
	-1.3094       = Validation score (-MASE)
	25.66   s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 31.1s.
	Ensemble weights: {'TemporalFusionTransformer': 1.0}
	-1.3094       = Validation score (-MASE)
	0.07    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 29.04 s
Best model: TemporalFusionTransformer
Best model score: -1.3094
Model not specified in predict, will default to the model with the best validation score: TemporalFusionTransformer
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_221215"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_221215'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       0.99 GB / 8.00 GB (12.3%)
Disk Space Avail:   24.14 GB / 228.27 GB (10.6%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 3,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 80 rows, 1 time series. Median time series length is 80 (min=80, max=80). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 23:12:15
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 59.9s of remaining time.
	-2.8148       = Validation score (-MASE)
	0.08    s     = Training runtime
	5.55    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 7.7s of the 54.1s of remaining time.
	-2.7876       = Validation score (-MASE)
	4.03    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 8.3s of the 50.0s of remaining time.
	-2.9272       = Validation score (-MASE)
	0.55    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 9.9s of the 49.4s of remaining time.
	-2.8148       = Validation score (-MASE)
	0.17    s     = Training runtime
	10.81   s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 9.5s of the 38.2s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 12.6s of the 37.9s of remaining time.
	-3.5093       = Validation score (-MASE)
	8.57    s     = Training runtime
	2.24    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 13.5s of the 27.1s of remaining time.
	-2.5280       = Validation score (-MASE)
	13.58   s     = Training runtime
	0.08    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 13.3s.
	Ensemble weights: {'TemporalFusionTransformer': 1.0}
	-2.5280       = Validation score (-MASE)
	0.15    s     = Training runtime
	0.08    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 46.96 s
Best model: TemporalFusionTransformer
Best model score: -2.5280
Model not specified in predict, will default to the model with the best validation score: TemporalFusionTransformer
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_221303"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_221303'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       0.98 GB / 8.00 GB (12.3%)
Disk Space Avail:   23.14 GB / 228.27 GB (10.1%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 3,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 81 rows, 1 time series. Median time series length is 81 (min=81, max=81). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 23:13:03
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	0.0000        = Validation score (-MASE)
	0.07    s     = Training runtime
	7.29    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 7.5s of the 52.5s of remaining time.
	-0.0075       = Validation score (-MASE)
	5.16    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 7.9s of the 47.2s of remaining time.
	-1.9328       = Validation score (-MASE)
	2.20    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 9.0s of the 44.8s of remaining time.
	Time limit exceeded... Skipping ETS.
Training timeseries model Theta. Training for up to 8.9s of the 35.7s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 11.9s of the 35.7s of remaining time.
	-1.5395       = Validation score (-MASE)
	1.02    s     = Training runtime
	1.15    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 16.7s of the 33.5s of remaining time.
	-1.5428       = Validation score (-MASE)
	15.89   s     = Training runtime
	0.23    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 17.0s.
	Ensemble weights: {'SeasonalNaive': 1.0}
	0.0000        = Validation score (-MASE)
	0.10    s     = Training runtime
	7.29    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 43.52 s
Best model: SeasonalNaive
Best model score: 0.0000
Model not specified in predict, will default to the model with the best validation score: SeasonalNaive
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_221350"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_221350'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       0.99 GB / 8.00 GB (12.4%)
Disk Space Avail:   23.13 GB / 228.27 GB (10.1%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 3,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 82 rows, 1 time series. Median time series length is 82 (min=82, max=82). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 23:13:50
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	0.0000        = Validation score (-MASE)
	0.02    s     = Training runtime
	2.74    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 7.9s of the 55.5s of remaining time.
	-0.0569       = Validation score (-MASE)
	3.49    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 8.7s of the 52.0s of remaining time.
	-1.7029       = Validation score (-MASE)
	0.43    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 10.3s of the 51.5s of remaining time.
	-0.0000       = Validation score (-MASE)
	0.01    s     = Training runtime
	8.15    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 10.8s of the 43.3s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 14.4s of the 43.2s of remaining time.
	-0.3242       = Validation score (-MASE)
	0.97    s     = Training runtime
	0.78    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 20.7s of the 41.5s of remaining time.
	-1.0059       = Validation score (-MASE)
	19.06   s     = Training runtime
	0.11    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 22.2s.
	Ensemble weights: {'SeasonalNaive': 1.0}
	0.0000        = Validation score (-MASE)
	0.15    s     = Training runtime
	2.75    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 38.28 s
Best model: SeasonalNaive
Best model score: 0.0000
Model not specified in predict, will default to the model with the best validation score: SeasonalNaive
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_221433"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_221433'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.00 GB / 8.00 GB (12.6%)
Disk Space Avail:   23.13 GB / 228.27 GB (10.1%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 3,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 83 rows, 1 time series. Median time series length is 83 (min=83, max=83). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 23:14:33
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 59.9s of remaining time.
	-0.1881       = Validation score (-MASE)
	0.03    s     = Training runtime
	1.39    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.3s of the 58.3s of remaining time.
	-0.1881       = Validation score (-MASE)
	5.57    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 8.8s of the 52.7s of remaining time.
	-0.6680       = Validation score (-MASE)
	0.39    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 10.5s of the 52.3s of remaining time.
	-0.1881       = Validation score (-MASE)
	0.02    s     = Training runtime
	6.35    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 11.5s of the 45.9s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 15.3s of the 45.8s of remaining time.
	-0.2919       = Validation score (-MASE)
	1.66    s     = Training runtime
	2.33    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 20.9s of the 41.8s of remaining time.
	-0.5449       = Validation score (-MASE)
	19.48   s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 22.3s.
	Ensemble weights: {'SeasonalNaive': 1.0}
	-0.1881       = Validation score (-MASE)
	0.08    s     = Training runtime
	1.39    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 37.85 s
Best model: SeasonalNaive
Best model score: -0.1881
Model not specified in predict, will default to the model with the best validation score: SeasonalNaive
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_221512"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_221512'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       0.98 GB / 8.00 GB (12.2%)
Disk Space Avail:   23.13 GB / 228.27 GB (10.1%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 3,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 84 rows, 1 time series. Median time series length is 84 (min=84, max=84). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 23:15:12
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-0.4762       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.39    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.5s of the 59.6s of remaining time.
	-0.4486       = Validation score (-MASE)
	1.08    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.7s of the 58.5s of remaining time.
	-1.0606       = Validation score (-MASE)
	0.47    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.6s of the 57.9s of remaining time.
	-0.4762       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.06    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.5s of the 57.9s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.3s of the 57.9s of remaining time.
	-0.4858       = Validation score (-MASE)
	0.94    s     = Training runtime
	0.41    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 28.3s of the 56.5s of remaining time.
	-0.3468       = Validation score (-MASE)
	25.75   s     = Training runtime
	0.06    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 30.6s.
	Ensemble weights: {'TemporalFusionTransformer': 1.0}
	-0.3468       = Validation score (-MASE)
	0.10    s     = Training runtime
	0.06    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 29.59 s
Best model: TemporalFusionTransformer
Best model score: -0.3468
Model not specified in predict, will default to the model with the best validation score: TemporalFusionTransformer
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_221541"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_221541'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       0.98 GB / 8.00 GB (12.2%)
Disk Space Avail:   23.13 GB / 228.27 GB (10.1%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 3,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 85 rows, 1 time series. Median time series length is 85 (min=85, max=85). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 23:15:41
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-0.5786       = Validation score (-MASE)
	0.01    s     = Training runtime
	2.62    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.2s of the 57.3s of remaining time.
	-0.5596       = Validation score (-MASE)
	0.55    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.5s of the 56.8s of remaining time.
	-1.2544       = Validation score (-MASE)
	0.42    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.3s of the 56.3s of remaining time.
	-0.5786       = Validation score (-MASE)
	0.01    s     = Training runtime
	1.60    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 13.7s of the 54.7s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 18.2s of the 54.7s of remaining time.
	-0.9004       = Validation score (-MASE)
	0.73    s     = Training runtime
	0.47    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 26.7s of the 53.5s of remaining time.
	-0.4206       = Validation score (-MASE)
	24.39   s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 29.0s.
	Ensemble weights: {'TemporalFusionTransformer': 1.0}
	-0.4206       = Validation score (-MASE)
	0.13    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 31.27 s
Best model: TemporalFusionTransformer
Best model score: -0.4206
Model not specified in predict, will default to the model with the best validation score: TemporalFusionTransformer
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_221613"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_221613'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.00 GB / 8.00 GB (12.4%)
Disk Space Avail:   23.13 GB / 228.27 GB (10.1%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 3,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 86 rows, 1 time series. Median time series length is 86 (min=86, max=86). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 23:16:13
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-0.6785       = Validation score (-MASE)
	0.04    s     = Training runtime
	3.98    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.0s of the 55.8s of remaining time.
	-0.7996       = Validation score (-MASE)
	17.84   s     = Training runtime
	0.07    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 6.3s of the 37.7s of remaining time.
	-0.9526       = Validation score (-MASE)
	1.92    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 7.1s of the 35.6s of remaining time.
	-0.6785       = Validation score (-MASE)
	0.01    s     = Training runtime
	5.30    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 7.6s of the 30.2s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 10.1s of the 30.2s of remaining time.
	-0.3522       = Validation score (-MASE)
	1.48    s     = Training runtime
	1.01    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 13.8s of the 27.7s of remaining time.
	-0.3800       = Validation score (-MASE)
	12.83   s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 14.6s.
	Ensemble weights: {'Chronos2': 1.0}
	-0.3522       = Validation score (-MASE)
	0.12    s     = Training runtime
	1.02    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 45.64 s
Best model: Chronos2
Best model score: -0.3522
Model not specified in predict, will default to the model with the best validation score: Chronos2
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_221701"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_221701'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.22 GB / 8.00 GB (15.2%)
Disk Space Avail:   23.14 GB / 228.27 GB (10.1%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 3,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 87 rows, 1 time series. Median time series length is 87 (min=87, max=87). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 23:17:02
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 59.9s of remaining time.
	-1.2709       = Validation score (-MASE)
	0.01    s     = Training runtime
	1.17    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.4s of the 58.6s of remaining time.
	-1.4524       = Validation score (-MASE)
	2.46    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.4s of the 56.1s of remaining time.
	-1.3440       = Validation score (-MASE)
	0.35    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.2s of the 55.8s of remaining time.
	-1.2709       = Validation score (-MASE)
	0.01    s     = Training runtime
	1.56    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 13.5s of the 54.2s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 18.1s of the 54.2s of remaining time.
	-0.7992       = Validation score (-MASE)
	0.82    s     = Training runtime
	0.89    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 26.2s of the 52.4s of remaining time.
	-0.1076       = Validation score (-MASE)
	23.83   s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 28.5s.
	Ensemble weights: {'TemporalFusionTransformer': 1.0}
	-0.1076       = Validation score (-MASE)
	0.31    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 31.80 s
Best model: TemporalFusionTransformer
Best model score: -0.1076
Model not specified in predict, will default to the model with the best validation score: TemporalFusionTransformer
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_221734"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_221734'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       0.96 GB / 8.00 GB (12.0%)
Disk Space Avail:   25.13 GB / 228.27 GB (11.0%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 3,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 88 rows, 1 time series. Median time series length is 88 (min=88, max=88). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 23:17:34
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-0.1951       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 59.9s of remaining time.
	-0.4611       = Validation score (-MASE)
	0.89    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.8s of the 59.0s of remaining time.
	-1.6008       = Validation score (-MASE)
	0.49    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.7s of the 58.4s of remaining time.
	-0.1952       = Validation score (-MASE)
	0.01    s     = Training runtime
	2.03    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.1s of the 56.4s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 18.8s of the 56.4s of remaining time.
	-1.4057       = Validation score (-MASE)
	0.86    s     = Training runtime
	0.66    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 27.4s of the 54.9s of remaining time.
	-0.1885       = Validation score (-MASE)
	25.13   s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 29.6s.
	Ensemble weights: {'DirectTabular': 0.03, 'TemporalFusionTransformer': 0.97}
	-0.1798       = Validation score (-MASE)
	0.14    s     = Training runtime
	0.06    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 30.60 s
Best model: WeightedEnsemble
Best model score: -0.1798
Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_221804"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_221804'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       0.98 GB / 8.00 GB (12.2%)
Disk Space Avail:   25.13 GB / 228.27 GB (11.0%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 3,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 89 rows, 1 time series. Median time series length is 89 (min=89, max=89). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 23:18:04
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-1.0859       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 59.9s of remaining time.
	-1.0282       = Validation score (-MASE)
	0.74    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.2s of remaining time.
	-1.2637       = Validation score (-MASE)
	0.51    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.7s of the 58.6s of remaining time.
	-1.0859       = Validation score (-MASE)
	0.01    s     = Training runtime
	3.66    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 13.7s of the 54.9s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 18.3s of the 54.9s of remaining time.
	-0.9439       = Validation score (-MASE)
	0.89    s     = Training runtime
	0.54    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 26.7s of the 53.5s of remaining time.
	-1.2549       = Validation score (-MASE)
	24.25   s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 29.1s.
	Ensemble weights: {'Chronos2': 0.52, 'SeasonalNaive': 0.48}
	-0.9171       = Validation score (-MASE)
	0.09    s     = Training runtime
	0.57    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 31.00 s
Best model: WeightedEnsemble
Best model score: -0.9171
Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_221836"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_221836'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.01 GB / 8.00 GB (12.6%)
Disk Space Avail:   25.12 GB / 228.27 GB (11.0%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 3,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 90 rows, 1 time series. Median time series length is 90 (min=90, max=90). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 23:18:36
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-1.7917       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.31    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.5s of the 59.7s of remaining time.
	-1.3791       = Validation score (-MASE)
	0.64    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.8s of the 59.0s of remaining time.
	-2.2792       = Validation score (-MASE)
	0.82    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.6s of the 58.2s of remaining time.
	-1.7917       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.06    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.5s of the 58.1s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.4s of the 58.1s of remaining time.
	-1.2885       = Validation score (-MASE)
	0.74    s     = Training runtime
	0.31    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 28.5s of the 57.0s of remaining time.
	-1.7133       = Validation score (-MASE)
	25.85   s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 31.1s.
	Ensemble weights: {'Chronos2': 1.0}
	-1.2885       = Validation score (-MASE)
	0.10    s     = Training runtime
	0.31    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 29.11 s
Best model: Chronos2
Best model score: -1.2885
Model not specified in predict, will default to the model with the best validation score: Chronos2
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_221907"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_221907'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.00 GB / 8.00 GB (12.5%)
Disk Space Avail:   25.12 GB / 228.27 GB (11.0%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 3,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 91 rows, 1 time series. Median time series length is 91 (min=91, max=91). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 23:19:07
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-4.0000       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.05    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 59.9s of remaining time.
	-3.5563       = Validation score (-MASE)
	0.89    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.8s of the 59.0s of remaining time.
	-4.3092       = Validation score (-MASE)
	0.61    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.7s of the 58.3s of remaining time.
	-3.9999       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.06    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.6s of the 58.3s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.4s of the 58.2s of remaining time.
	-3.3864       = Validation score (-MASE)
	1.27    s     = Training runtime
	0.37    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 28.3s of the 56.6s of remaining time.
	-3.4901       = Validation score (-MASE)
	25.67   s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 30.9s.
	Ensemble weights: {'Chronos2': 1.0}
	-3.3864       = Validation score (-MASE)
	0.09    s     = Training runtime
	0.37    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 29.25 s
Best model: Chronos2
Best model score: -3.3864
Model not specified in predict, will default to the model with the best validation score: Chronos2
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_221937"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_221937'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.04 GB / 8.00 GB (13.0%)
Disk Space Avail:   25.12 GB / 228.27 GB (11.0%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 3,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 92 rows, 1 time series. Median time series length is 92 (min=92, max=92). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 23:19:37
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-2.3467       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.27    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.5s of the 59.7s of remaining time.
	-1.8406       = Validation score (-MASE)
	0.48    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.2s of remaining time.
	-5.2427       = Validation score (-MASE)
	2.17    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.4s of the 57.0s of remaining time.
	-2.3470       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.11    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.2s of the 56.8s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 18.9s of the 56.8s of remaining time.
	-1.6579       = Validation score (-MASE)
	0.72    s     = Training runtime
	0.30    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 27.9s of the 55.8s of remaining time.
	-4.8959       = Validation score (-MASE)
	25.25   s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 30.5s.
	Ensemble weights: {'Chronos2': 1.0}
	-1.6579       = Validation score (-MASE)
	0.08    s     = Training runtime
	0.30    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 29.61 s
Best model: Chronos2
Best model score: -1.6579
Model not specified in predict, will default to the model with the best validation score: Chronos2
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_222007"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_222007'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.01 GB / 8.00 GB (12.7%)
Disk Space Avail:   25.11 GB / 228.27 GB (11.0%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 3,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 93 rows, 1 time series. Median time series length is 93 (min=93, max=93). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 23:20:07
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-4.3511       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 59.9s of remaining time.
	-4.4183       = Validation score (-MASE)
	0.48    s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.4s of remaining time.
	-6.6921       = Validation score (-MASE)
	0.39    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.8s of the 59.0s of remaining time.
	-4.3511       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.05    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.7s of the 59.0s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.7s of the 59.0s of remaining time.
	-3.3945       = Validation score (-MASE)
	0.73    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 29.1s of the 58.2s of remaining time.
	-6.9206       = Validation score (-MASE)
	26.34   s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 31.8s.
	Ensemble weights: {'Chronos2': 1.0}
	-3.3945       = Validation score (-MASE)
	0.10    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 28.32 s
Best model: Chronos2
Best model score: -3.3945
Model not specified in predict, will default to the model with the best validation score: Chronos2
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_222037"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_222037'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.08 GB / 8.00 GB (13.4%)
Disk Space Avail:   25.11 GB / 228.27 GB (11.0%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 3,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 94 rows, 1 time series. Median time series length is 94 (min=94, max=94). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 23:20:37
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-2.3226       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.11    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.5s of the 59.8s of remaining time.
	-1.9932       = Validation score (-MASE)
	0.71    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.1s of remaining time.
	-7.5675       = Validation score (-MASE)
	0.44    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.7s of the 58.6s of remaining time.
	-2.3229       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.6s of the 58.6s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.5s of the 58.6s of remaining time.
	-0.8322       = Validation score (-MASE)
	0.77    s     = Training runtime
	0.27    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 28.8s of the 57.5s of remaining time.
	-7.0716       = Validation score (-MASE)
	26.05   s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 31.4s.
	Ensemble weights: {'Chronos2': 1.0}
	-0.8322       = Validation score (-MASE)
	0.11    s     = Training runtime
	0.27    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 28.72 s
Best model: Chronos2
Best model score: -0.8322
Model not specified in predict, will default to the model with the best validation score: Chronos2
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_222107"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_222107'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.07 GB / 8.00 GB (13.4%)
Disk Space Avail:   25.11 GB / 228.27 GB (11.0%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 3,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 95 rows, 1 time series. Median time series length is 95 (min=95, max=95). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-14 23:21:07
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-1.7389       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 59.9s of remaining time.
	-0.9825       = Validation score (-MASE)
	0.58    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.3s of remaining time.
	-7.9735       = Validation score (-MASE)
	0.73    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.7s of the 58.6s of remaining time.
	-1.7390       = Validation score (-MASE)
	0.00    s     = Training runtime
	0.10    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.6s of the 58.5s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.5s of the 58.4s of remaining time.
	-0.4647       = Validation score (-MASE)
	0.72    s     = Training runtime
	0.30    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 28.7s of the 57.4s of remaining time.
	-7.2785       = Validation score (-MASE)
	25.96   s     = Training runtime
	0.01    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 31.4s.
	Ensemble weights: {'Chronos2': 1.0}
	-0.4647       = Validation score (-MASE)
	0.09    s     = Training runtime
	0.30    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 28.72 s
Best model: Chronos2
Best model score: -0.4647
Model not specified in predict, will default to the model with the best validation score: Chronos2
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_230905"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_230905'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       0.97 GB / 8.00 GB (12.2%)
Disk Space Avail:   25.19 GB / 228.27 GB (11.0%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 6,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 80 rows, 1 time series. Median time series length is 80 (min=80, max=80). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-15 00:09:05
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-1.3519       = Validation score (-MASE)
	0.01    s     = Training runtime
	2.74    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.2s of the 57.1s of remaining time.
	-1.0800       = Validation score (-MASE)
	0.47    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.4s of the 56.6s of remaining time.
	-5.2268       = Validation score (-MASE)
	0.48    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.2s of the 56.1s of remaining time.
	-1.3519       = Validation score (-MASE)
	0.02    s     = Training runtime
	2.56    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 13.4s of the 53.5s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 17.8s of the 53.5s of remaining time.
	-1.2027       = Validation score (-MASE)
	1.37    s     = Training runtime
	0.68    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 25.7s of the 51.4s of remaining time.
	-2.9494       = Validation score (-MASE)
	23.35   s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 28.0s.
	Ensemble weights: {'RecursiveTabular': 0.95, 'TemporalFusionTransformer': 0.05}
	-1.0737       = Validation score (-MASE)
	0.08    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 32.11 s
Best model: WeightedEnsemble
Best model score: -1.0737
Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_230937"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_230937'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       0.98 GB / 8.00 GB (12.3%)
Disk Space Avail:   25.19 GB / 228.27 GB (11.0%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 6,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 81 rows, 1 time series. Median time series length is 81 (min=81, max=81). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-15 00:09:37
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-1.8272       = Validation score (-MASE)
	0.01    s     = Training runtime
	1.62    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.3s of the 58.3s of remaining time.
	-1.3433       = Validation score (-MASE)
	1.06    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.5s of the 57.2s of remaining time.
	-5.9088       = Validation score (-MASE)
	0.34    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.4s of the 56.8s of remaining time.
	-1.8272       = Validation score (-MASE)
	0.01    s     = Training runtime
	3.49    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 13.3s of the 53.3s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 17.8s of the 53.3s of remaining time.
	-2.0973       = Validation score (-MASE)
	0.79    s     = Training runtime
	0.52    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 26.0s of the 52.0s of remaining time.
	-1.4457       = Validation score (-MASE)
	23.66   s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 28.2s.
	Ensemble weights: {'RecursiveTabular': 0.65, 'TemporalFusionTransformer': 0.35}
	-1.3242       = Validation score (-MASE)
	0.09    s     = Training runtime
	0.06    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 31.96 s
Best model: WeightedEnsemble
Best model score: -1.3242
Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_231009"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_231009'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       0.98 GB / 8.00 GB (12.3%)
Disk Space Avail:   25.18 GB / 228.27 GB (11.0%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 6,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 82 rows, 1 time series. Median time series length is 82 (min=82, max=82). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-15 00:10:09
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-2.3148       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.07    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.6s of the 59.9s of remaining time.
	-2.2356       = Validation score (-MASE)
	0.68    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.9s of the 59.1s of remaining time.
	-6.3268       = Validation score (-MASE)
	0.44    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.7s of the 58.7s of remaining time.
	-2.3148       = Validation score (-MASE)
	0.00    s     = Training runtime
	1.10    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 14.4s of the 57.6s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 19.2s of the 57.6s of remaining time.
	-2.9602       = Validation score (-MASE)
	0.74    s     = Training runtime
	0.46    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 28.2s of the 56.4s of remaining time.
	-1.0596       = Validation score (-MASE)
	25.51   s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Fitting 1 ensemble(s), in 1 layers.
Training ensemble model WeightedEnsemble. Training for up to 30.8s.
	Ensemble weights: {'TemporalFusionTransformer': 1.0}
	-1.0596       = Validation score (-MASE)
	0.07    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Chronos2', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 29.32 s
Best model: TemporalFusionTransformer
Best model score: -1.0596
Model not specified in predict, will default to the model with the best validation score: TemporalFusionTransformer
No path specified. Models will be saved in: "AutogluonModels/ag-20260114_231038"
Beginning AutoGluon training... Time limit = 60s
AutoGluon will save models to '/Users/vinitasable/Documents/ABA Project Seminar/Polymer_Dashboard_project/AutogluonModels/ag-20260114_231038'
=================== System Info ===================
AutoGluon Version:  1.5.0
Python Version:     3.13.3
Operating System:   Darwin
Platform Machine:   arm64
Platform Version:   Darwin Kernel Version 25.1.0: Mon Oct 20 19:34:03 PDT 2025; root:xnu-12377.41.6~2/RELEASE_ARM64_T8112
CPU Count:          8
Pytorch Version:    2.9.1
CUDA Version:       CUDA is not available
GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)
Memory Avail:       1.07 GB / 8.00 GB (13.3%)
Disk Space Avail:   25.18 GB / 228.27 GB (11.0%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'W-FRI',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 6,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 60,
 'verbosity': 2}

Provided train_data has 83 rows, 1 time series. Median time series length is 83 (min=83, max=83). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2026-01-15 00:10:38
Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos2', 'TemporalFusionTransformer']
Training timeseries model SeasonalNaive. Training for up to 7.5s of the 60.0s of remaining time.
	-2.7210       = Validation score (-MASE)
	0.01    s     = Training runtime
	2.30    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 8.2s of the 57.7s of remaining time.
	-2.7093       = Validation score (-MASE)
	0.48    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 9.5s of the 57.1s of remaining time.
	-3.4466       = Validation score (-MASE)
	0.49    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 11.3s of the 56.6s of remaining time.
	-2.7210       = Validation score (-MASE)
	0.01    s     = Training runtime
	2.29    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 13.6s of the 54.3s of remaining time.
	Time limit exceeded... Skipping Theta.
Training timeseries model Chronos2. Training for up to 18.1s of the 54.3s of remaining time.
	-3.6478       = Validation score (-MASE)
	0.85    s     = Training runtime
	0.44    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 26.5s of the 53.0s of remaining time.
	-1.5613       = Validation score (-MASE)
	23.97   s     = Training runtime
	0.01    s     = Validation (prediction) runtime
